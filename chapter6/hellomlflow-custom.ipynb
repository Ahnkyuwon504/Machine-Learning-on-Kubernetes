{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to verify Mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import mlflow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "import mlflow_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "y = np.dot(X, np.array([1, 2])) + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Mlflow\n",
    "You will put the location of Mlflow server. Note that becuase your notebook and the Mlflow server is running on Kubernetes, we just put the location of Kubernetes Service. \n",
    "\n",
    "We are using our local Minio server as the S3 storage and therefore pass the variables named AWS_SECRET_ACCESS_KEY containing the password.\n",
    "\n",
    "### Experiment Name\n",
    "This is one important variable via which all of your experiment runs will be stored in the Mlflow server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"http://mlflow:5500\"\n",
    "\n",
    "EXPERIMENT_NAME = \"HelloMlFlowCustom\"\n",
    "\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL']='http://minio-ml-workshop:9000'\n",
    "os.environ['AWS_ACCESS_KEY_ID']='minio'\n",
    "# os.environ['AWS_SECRET_ACCESS_KEY']='minio123'\n",
    "os.environ['AWS_REGION']='us-east-1'\n",
    "os.environ['AWS_BUCKET_NAME']='mlflow'\n",
    "\n",
    "# Connect to local MLflow tracking server\n",
    "mlflow.set_tracking_uri(HOST)\n",
    "\n",
    "# Set the experiment name through which you will label all your exerpiments runs\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# enable autologging for scikit\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = DecisionTreeClassifier(max_depth=5, criterion='gini',min_samples_leaf = 3 ,min_samples_split = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding custom tags to the run\n",
    "Mlflow api allows to associate the custom tags as shown below. \n",
    "\n",
    "record_libraries is a custom function which runs the pip freeze command and store it as a file to the mlflow run. You can find this function in the associated mlflow_util class in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_git_revision_hash' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-156ddb4892db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m with mlflow.start_run(tags={\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m\"mlflow.source.git.commit\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mget_git_revision_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"mlflow.source.git.branch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_git_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"mlflow.source.type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"NOTEBOOK\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"mlflow.source.git.repoURL\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_git_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_git_revision_hash' is not defined"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(tags={\n",
    "    \"mlflow.source.git.commit\" : get_git_revision_hash() ,\n",
    "    \"mlflow.source.git.branch\": get_git_branch(),\n",
    "    \"mlflow.source.type\": \"NOTEBOOK\",\n",
    "    \"mlflow.source.git.repoURL\": get_git_remote()\n",
    "    }) as run:\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    record_libraries(mlflow)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e7fc2f0a6d874598201e2b1c6d4c9c1ff81a6579125fac8bdb7060863303db5"
  },
  "kernelspec": {
   "display_name": "3.8.11",
   "language": "python",
   "name": "3.8.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
